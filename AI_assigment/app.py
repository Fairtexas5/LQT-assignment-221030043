import gradio as gr
import os
import uuid
import tempfile
from typing import List, Tuple, Optional
from config import Config
from pdf_processor import PDFProcessor
from vector_store import VectorStore
from rag_engine import RAGEngine

# Initialize components
pdf_processor = PDFProcessor(
    chunk_size=Config.CHUNK_SIZE,
    chunk_overlap=Config.CHUNK_OVERLAP
)

vector_store = VectorStore(
    model_name=Config.EMBEDDING_MODEL,
    vector_db_path=Config.VECTOR_DB_PATH
)

rag_engine = RAGEngine(vector_store)

def upload_and_process_pdfs(files: List[tempfile._TemporaryFileWrapper]) -> str:
    """Process uploaded PDF files and add them to the vector store."""
    if not files:
        return "âŒ No files uploaded."

    try:
        uploaded_files = []
        total_chunks = 0

        for file in files:
            if file is None:
                continue

            file_path = file.name
            filename = os.path.basename(file_path)

            # Check if it's a PDF
            if not filename.lower().endswith('.pdf'):
                continue

            # Process PDF
            chunks = pdf_processor.extract_text_from_pdf(file_path)

            # Add to vector store
            vector_store.add_documents(chunks)

            uploaded_files.append(filename)
            total_chunks += len(chunks)

        if uploaded_files:
            stats = vector_store.get_stats()
            return f"âœ… Successfully processed {len(uploaded_files)} PDF(s):\n" + \
                   f"ğŸ“„ Files: {', '.join(uploaded_files)}\n" + \
                   f"ğŸ“Š Total chunks created: {total_chunks}\n" + \
                   f"ğŸ—ƒï¸ Database now contains {stats['total_documents']} total documents"
        else:
            return "âŒ No valid PDF files found."

    except Exception as e:
        return f"âŒ Error processing files: {str(e)}"

def get_database_stats() -> str:
    """Get current database statistics."""
    stats = vector_store.get_stats()
    return f"ğŸ“Š **Database Statistics**\n\n" + \
           f"ğŸ“„ Total Documents: {stats['total_documents']}\n" + \
           f"ğŸ” Index Size: {stats['index_size']}\n" + \
           f"ğŸ“ Vector Dimension: {stats.get('dimension', 'N/A')}"

def clear_database() -> str:
    """Clear the entire vector database."""
    try:
        vector_store.clear_index()
        return "âœ… Database cleared successfully!"
    except Exception as e:
        return f"âŒ Error clearing database: {str(e)}"

def respond(message: str, chat_history: List[dict]) -> Tuple[str, List[dict]]:
    """Chat function that handles the new messages format."""
    if not message.strip():
        return "", chat_history

    try:
        # Get response from RAG engine
        result = rag_engine.generate_answer(message, top_k=Config.TOP_K)

        response = result['answer']
        sources = result.get('sources', [])

        # Add source information to response
        if sources:
            response += "\n\n**ğŸ“š Sources:**\n"
            for i, source in enumerate(sources[:3], 1):
                response += f"{i}. ğŸ“„ **{source['source_file']}** (Page {source['page_number']})\n"
                response += f"   ğŸ“ _{source['content_preview']}_\n"

        # Add user message to chat history
        chat_history.append({"role": "user", "content": message})

        # Add assistant response to chat history
        chat_history.append({"role": "assistant", "content": response})

        return "", chat_history

    except Exception as e:
        error_response = f"âŒ Error: {str(e)}"

        # Add user message and error response to chat history
        chat_history.append({"role": "user", "content": message})
        chat_history.append({"role": "assistant", "content": error_response})

        return "", chat_history

def create_interface():
    """Create the Gradio interface."""

    with gr.Blocks(title="PDF RAG System") as interface:

        # Header
        gr.Markdown("# ğŸ¤– PDF RAG Assistant")
        gr.Markdown("Upload PDFs and ask intelligent questions about their content using AI")

        with gr.Tabs():

            # Tab 1: Document Management
            with gr.Tab("ğŸ“ Document Management"):

                with gr.Row():
                    with gr.Column(scale=2):
                        gr.Markdown("## ğŸ“¤ Upload PDF Documents")
                        gr.Markdown("Drag and drop your PDF files or click to browse")

                        file_upload = gr.File(
                            file_count="multiple",
                            file_types=[".pdf"],
                            label="Select PDF files to upload"
                        )

                        upload_btn = gr.Button(
                            "ğŸš€ Process PDFs",
                            variant="primary",
                            size="lg"
                        )

                        upload_status = gr.Textbox(
                            label="ğŸ“Š Upload Status",
                            interactive=False,
                            max_lines=8
                        )

                    with gr.Column(scale=1):
                        gr.Markdown("## ğŸ—„ï¸ Database Management")

                        stats_display = gr.Markdown(get_database_stats())

                        with gr.Row():
                            refresh_btn = gr.Button("ğŸ”„ Refresh", size="sm", variant="secondary")
                            clear_btn = gr.Button("ğŸ—‘ï¸ Clear Database", size="sm", variant="stop")

                        clear_status = gr.Textbox(
                            label="ğŸ”§ Database Status",
                            interactive=False,
                            max_lines=3
                        )

                # Event handlers for document management
                def update_stats_display():
                    return get_database_stats()

                upload_btn.click(
                    fn=upload_and_process_pdfs,
                    inputs=[file_upload],
                    outputs=[upload_status]
                ).then(
                    fn=update_stats_display,
                    outputs=[stats_display]
                )

                refresh_btn.click(
                    fn=update_stats_display,
                    outputs=[stats_display]
                )

                clear_btn.click(
                    fn=clear_database,
                    outputs=[clear_status]
                ).then(
                    fn=update_stats_display,
                    outputs=[stats_display]
                )

            # Tab 2: Chat Interface
            with gr.Tab("ğŸ’¬ AI Assistant"):

                gr.Markdown("## ğŸ¤– Ask questions about your uploaded documents")
                gr.Markdown("**ğŸ’¡ Tips:** Upload PDFs first, then ask specific questions about their content for detailed answers with source references.")

                # Create chat interface with messages format
                chatbot = gr.Chatbot(
                    height=500,
                    show_label=False,
                    type="messages",
                    value=[{
                        "role": "assistant",
                        "content": "ğŸ‘‹ **Welcome to PDF RAG Assistant!**\n\nI'm here to help you analyze and understand your PDF documents. \n\nğŸ“‹ **Getting started:**\n1. Upload PDFs in the 'Document Management' tab\n2. Come back here and ask me questions\n3. I'll provide detailed answers with source references\n\nğŸš€ **Ready to get started?**"
                    }]
                )

                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="ğŸ’­ Ask a question about your documents...",
                        label="Your Question",
                        lines=2,
                        scale=4
                    )
                    send_btn = gr.Button(
                        "ğŸ“¨ Send",
                        variant="primary",
                        size="lg",
                        scale=1
                    )

                clear_chat_btn = gr.Button(
                    "ğŸ§¹ Clear Chat",
                    variant="secondary",
                    size="sm"
                )

                # Event handlers for chat
                send_btn.click(
                    fn=respond,
                    inputs=[msg_input, chatbot],
                    outputs=[msg_input, chatbot]
                )

                msg_input.submit(
                    fn=respond,
                    inputs=[msg_input, chatbot],
                    outputs=[msg_input, chatbot]
                )

                clear_chat_btn.click(
                    fn=lambda: [{
                        "role": "assistant",
                        "content": "ğŸ‘‹ **Welcome back!**\n\nI'm ready to help you with your PDF documents again. What would you like to know?"
                    }],
                    outputs=[chatbot]
                )

            # Tab 3: System Information
            with gr.Tab("â„¹ï¸ System Information"):

                gr.Markdown("# âš™ï¸ System Configuration & Information")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("## ğŸ”§ Current Settings")

                        settings_info = f"""
**ğŸ§  Embedding Model:** `{Config.EMBEDDING_MODEL}`

**ğŸ“ Chunk Size:** {Config.CHUNK_SIZE} characters

**ğŸ”— Chunk Overlap:** {Config.CHUNK_OVERLAP} characters

**ğŸ¯ Search Results:** Top {Config.TOP_K} most relevant chunks

**ğŸ“ Max File Size:** 16MB per PDF
"""
                        gr.Markdown(settings_info)

                    with gr.Column():
                        gr.Markdown("## ğŸš€ Key Features")

                        features_info = """
âœ… Multiple PDF upload and processing

âœ… Intelligent text chunking

âœ… Vector similarity search using FAISS

âœ… AI-powered Q&A with Google Gemini

âœ… Source attribution with page numbers

âœ… Persistent vector database storage

âœ… Real-time chat interface

âœ… Responsive modern UI
"""
                        gr.Markdown(features_info)

                gr.Markdown("## ğŸ› ï¸ Technology Stack")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("**ğŸ–¥ï¸ Framework:** Gradio 4.44+")
                        gr.Markdown("**ğŸ“„ PDF Processing:** PyMuPDF")
                    with gr.Column():
                        gr.Markdown("**ğŸ§® Embeddings:** Sentence Transformers")
                        gr.Markdown("**ğŸ—ƒï¸ Vector Database:** FAISS")
                    with gr.Column():
                        gr.Markdown("**ğŸ¤– Language Model:** Google Gemini 1.5")

                gr.Markdown("## ğŸ“ Quick Start Guide")

                guide_info = """
**1.** Upload Documents - Go to 'Document Management' tab and upload your PDF files

**2.** Process & Index - Wait for the system to extract text and create embeddings

**3.** Ask Questions - Switch to 'AI Assistant' tab and start asking questions

**4.** Get Intelligent Answers - Receive detailed responses with source references and page numbers
"""
                gr.Markdown(guide_info)

    return interface

if __name__ == "__main__":
    # Create and launch the interface
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
